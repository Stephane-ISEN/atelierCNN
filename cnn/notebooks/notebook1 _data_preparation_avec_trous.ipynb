{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################################\n",
    "##############################################################################\n",
    "### **Atelier \"Comprendre et développer des CNN pour le traitement d'images\"**\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "#### **Partie 1 : Préparation des données** \n",
    "\n",
    "Dans cette introduction, nous allons apprendre à préparer les données pour qu'ils soient prêts à être utilisés pour un apprentissage par CNN\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "############################################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Préparation de l'environnement**\n",
    "\n",
    "Nous utiliserons Pillow, NumPy, Matplotlib et torchvision pour les transformations.\n",
    "\n",
    "- Pillow : librairie de manipulation d'images\n",
    "- Numpy : librairie de manipulation de tableau\n",
    "- torchvision : package de Pytorch spécialisé dans la computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import urllib.request\n",
    "\n",
    "# Fonction pour afficher une image\n",
    "def display_image(img, title=\"\"):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    # Si l'image est un tenseur PyTorch, on la convertit en NumPy\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.permute(1, 2, 0).numpy()  # De [C,H,W] à [H,W,C]\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Téléchargeons une image d'exemple depuis le web\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Si%C3%A8ge_social_de_l%27Ifremer.jpg/1024px-Si%C3%A8ge_social_de_l%27Ifremer.jpg\"\n",
    "urllib.request.urlretrieve(url, \"sample_image.png\")\n",
    "\n",
    "# Chargement de l'image\n",
    "img = Image.open(\"sample_image.png\").convert('RGB')\n",
    "display_image(img, \"Image originale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Etape 1 : redimensionnement**\n",
    "\n",
    "Les CNN exigent de traiter des datasets dont toutes les images ont la même taille. Nous allons donc redimensionner l'image en taille 300x300 pour l'exercice. Pour ceci, nous allons utiliser l'utilitaire transforms de torchvision. Nous retrouverons régulièrement cette utilitaire\n",
    "\n",
    "<br>\n",
    "\n",
    "NB : En pratique, il faudra redimensionner toutes ses images dans le format d'entrée du modèle CNN que l'on compte entrainer\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Completez l'argument d'interpolation à partir de la documentation\n",
    "#################################################################################\n",
    "resize_transform = transforms.Resize((300, 300), interpolation=\n",
    "\n",
    "# Application du redimensionnement\n",
    "img_resized = resize_transform(img)\n",
    "img_resized_array = np.array(img_resized)\n",
    "\n",
    "# Affichage\n",
    "display_image(img_resized_array, \"Image redimensionnée (300x300)\")\n",
    "\n",
    "# Vérification des dimensions\n",
    "print(f\"Dimensions de l'image redimensionnée : {img_resized_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### A vous de jouer ! Redimensionnez l'image en 128x128 et comparez la qualité\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Etape 2 : Normalisation des valeurs des pixels** \n",
    "\n",
    "L'intéret de cette normalisation réside dans l'aide qu'on apporte à l'optimiseur pour qu'il converge plus facilement lors de l'apprentissage.\n",
    "\n",
    "Nous allons donc appliquer une transformation aux valeurs de pixels.\n",
    "\n",
    "Pour chaque pixel de valeur v : v_nouveau = (v - mean)/std\n",
    "\n",
    "\n",
    "Le mean et la std appliqués sont généralement calculés sur les propriétés du dataset d'apprentissage (Exemple : Imagenet : mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225])\n",
    "\n",
    "Dans notre cas, nous n'avons pas le dataset, on appliquera arbitrairement une mean de 0.5 et une std de 0.3\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On transforme l'image en objet Tensor\n",
    "to_tensor = transforms.ToTensor()  \n",
    "img_tensor = to_tensor(img_resized)\n",
    "\n",
    "# Affichage des valeurs avant/après\n",
    "print(\"Valeurs avant normalisation (premiers 5 pixels, canal R) :\")\n",
    "print(np.array(img_resized)[0, 0, :5])\n",
    "\n",
    "#################################################################################\n",
    "# Completez les arguments de normalisation\n",
    "#################################################################################\n",
    "normalize = transforms.Normalize(\n",
    "\n",
    "img_normalized = normalize(img_tensor)\n",
    "\n",
    "print(\"Valeurs après normalisation ImageNet (premiers 5 pixels, canal R) :\")\n",
    "print(img_normalized[0, 0, :5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### A vous de jouer ! Normalisez l'image initiales à partir des statistiques de l'image, soit sa moyenne et sa std\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Etape 3 : l'augmentation de données**\n",
    "\n",
    "Les performances d'un modèle d'IA dépend fortement du nombre d'éléments du dataset d'entrainement. Il est donc souvent conseillé d'augmenter le jeu de données par des méthodes artificielles.\n",
    "\n",
    "Avec **torchvision.transforms**, on peut composer des augmentations aléatoires pour enrichir les données. Le but est d'augmenter le domaine de généralisation du futur modèle\n",
    "\n",
    "Dans l'exemple suivant, on va créer :\n",
    " - une rotation aléatoire allant jusqu'à 40°\n",
    " - un flip horizontal\n",
    " - un décalage \n",
    " - une déformation\n",
    " - un zoom\n",
    "\n",
    " <br>\n",
    "\n",
    " Dans les faits, il faut choisir des transformations réalistes pour notre cas d'usage. Si nous faisons un apprentissage sur des plaques d'immatriculation, il est très peu probable de visualiser des plaques retournées à 180°, il semble logique de ne pas appliquer de rotations trop importantes\n",
    "\n",
    " <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Completez les arguments des éléments de transformation pour la data augmentation\n",
    "#################################################################################\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(,              # Rotation aléatoire jusqu'à 40°\n",
    "    transforms.RandomHorizontalFlip(,          # Retournement horizontal\n",
    "    transforms.RandomAffine(),  # Décalage et déformation\n",
    "    transforms.RandomResizedCrop(,  # Zoom aléatoire\n",
    "    transforms.ToTensor(),                      # Conversion en tenseur\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.3,0.3,0.3])  # Normalisation\n",
    "])\n",
    "\n",
    "# Génération de 4 images augmentées\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(4):\n",
    "    img_augmented = augment_transform(img)\n",
    "    # Dénormalisation pour affichage\n",
    "    img_display = img_augmented.clone()\n",
    "    for c, m, s in zip(range(3), [0.5,0.5,0.5], [0.3,0.3,0.3]):\n",
    "        img_display[c] = img_display[c] * s + m\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(img_display.permute(1, 2, 0).numpy())\n",
    "    plt.title(f\"Image augmentée {i+1}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### A vous de jouer ! Ajoutez une transformation pour modifier la luminosité et le contraste de l'image. Son nom ? ColorJitter\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

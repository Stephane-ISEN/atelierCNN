{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################################\n",
    "##############################################################################\n",
    "### **Atelier \"Comprendre et développer des CNN pour le traitement d'images\"**\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### **Partie 3 : Développement d'un CNN de classification d'images satellitaires par finetuning** \n",
    "\n",
    "\n",
    "Dans cette trois partie, nous allons développer un modèle CNN  à partir d'un modèle de fondation afin de classifier correctement des images satellitaires de 4 types : désert, foret, océan et nuageux.\n",
    "\n",
    "<br>\n",
    "\n",
    "Les modèles de fondation sont de très gros modèles ayant appris à classifier souvent une grande quantité de classes. Le \"savoir\" contenu à l'intérieur permet de les réentrainer sur des datasets extrèmement différents, où ils vont montrer de très bonnes performances très rapidement, souvent meilleurs que les modèles \" from scratch\". C'est ce que nous allons tenter de démontrer ici\n",
    "<br>\n",
    "<br>\n",
    "############################################################\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "#### **Import des librairies utiles pour l'atelier**\n",
    "\n",
    "L'atelier se base sur **Pytorch**, un framework qui a énormément gagné en popularité ces dernières années. \n",
    "\n",
    "**TorchVision** est lui un package spécialement tourné vers la Computer Vision, et permet l'accès facile à des datasets publics, de créer aisement ses propres datasets. Il contient aussi nativement les principaux modèlesde fondation Open-Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vérification de la présence de capacité de calcul GPU sur l'ordinateur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Etape 1 : Chargement du modèle de fondation à finetuner**\n",
    "\n",
    "Le Finetuning requiert un modèle de fondation. Pytorch permet d'en charger directement. Nous choisissons ici mobilenet_v3_small, un modèle léger mais performant. \n",
    "\n",
    "<br>\n",
    "Ce modèle est concu pour classifier 1000 classes, il a donc 1000 neurones dans sa dernière couche. Nous avons 4 classes, nous allons donc remplacer la dernière couche du modèle (model.classifier[3]) par une couche qui va relier l'avant-dernière couche model.classifier[3].in_features à une couche à 4 neurones.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Nous allons vouloir utiliser le \"savoir\" contenu dans le modèle, donc nous souhaitons dans un premier temps seulement réentrainer les poids de la dernière couche du modèle. C'est donc du Transfer Learning que nous effectuerons plutot que du finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False  # Gel des couches convolutives\n",
    "\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = False  # Gel des couches fully connected\n",
    "\n",
    "\n",
    "for param in model.classifier[3].parameters():\n",
    "    param.requires_grad = True  # Permet l'entraînement uniquement sur la dernière couche\n",
    "\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "#### **Etape 2 : chargement du Dataset et transformation des données pour qu'elles soient utilisables par un modèle CNN**\n",
    "\n",
    "\n",
    "\n",
    "Nous allons maintenant transformer les images pour qu'elles aient : \n",
    "- La taille requise pour être entrée dans le modèle que nous allons finetuner : 224 pixels par 224 pixels\n",
    "- Un format qui soit un tensor Pytorch, afin d'être intégré au Pipeline Pytorch\n",
    "- Une normalisation des données des images sur les 3 canaux, R, G et B. On choisit ici les valeurs associée\n",
    "\n",
    "<br>\n",
    "\n",
    "Nous allons utiliser l'utilitaire **Transforms de TorchVision** qui va automatiser le pré-traitement des datasets\n",
    "\n",
    "<br>\n",
    "\n",
    "Ce modèle a été entrainé sur ImageNet, nous allons donc normaliser nos datas avec les propriétés d'ImageNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Chargement du Dataset avec l'utilitaire datasets de TorchVision**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Code_ML/Code/Atelier CNN/data/\"  # Adjust if dataset path differs\n",
    "\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(f\"Total Images: {len(full_dataset)}\")\n",
    "print(f\"Classes: {full_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "#### **Split du dataset**\n",
    "\n",
    "Selon les bonnes pratiques du ML, nous allons spliter notre dataset en jeu de Train, Validation et Test. Nous allons ensuite les convertir en Loaders, qui permettront une manipulation optimale ultérieurement.\n",
    "\n",
    "\n",
    "Le paramètre \"Batch size\" détermine la taille des batchs servant à itérer pour chaque mise à jour des poids.\n",
    "\n",
    "\n",
    "On pourrait passer 1 image à la fois ou à l'inverse, tout le dataset, mais ce n'est pas optimal. Passer des batchs de taille adaptée permet de gagner en efficacité d'entrainemenet et en stabilité des gradients\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Etape 3 : entrainement**\n",
    "\n",
    "\n",
    "Nous allons maintenant procéder à l'entrainement du modèle.\n",
    "\n",
    "\n",
    "Nous commencons par définir la métrique liée à la fonction de cout (ici l'entropie croisée)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Nous définissons ensuite l'**optimizer**, le grand classique étant Adam.\n",
    "\n",
    "Regardons le paramètre lr ou **learning rate**:\n",
    "Ce paramètre détermine l'intensité de mise à jour des poids du modèle. Ceci signifie qu'un lr trop grand engendre de fortes variations et donc une forte instabilité, alors qu'un lr trop faible rendrait très lent l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant entrainer le modèle sur un certain nombre d'époques, ici 5.\n",
    "\n",
    "Lors de chaque époque, le modèle va s'entrainer sur tous les éléments du dataset de train , puis sera évalué sur le dataset de validation.\n",
    "\n",
    "Par rapport à l'entrainement \"from scratch\", nous manipulons des modèles plus gros, nous allons donc sauvegarder le modèle à chaque époque (si il est le meilleur) afin de pouvoir le charger ultérieurement en cas d'échecs de l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "best_val_loss = float('inf')  # Initialiser la meilleure loss\n",
    "best_model_wts = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    \n",
    "    #################################################################################\n",
    "    # Completez le calcul de la train_loss\n",
    "    #################################################################################\n",
    "    train_loss = \n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    #################################################################################\n",
    "    # Completez le calcul de la val_loss\n",
    "    #################################################################################\n",
    "    val_loss = \n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    #################################################################################\n",
    "    # Completez la condition pour enregistrer le modèle courant\n",
    "    #################################################################################\n",
    "    \n",
    "    if val_loss < \n",
    "        best_val_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, \"best_model.pth\")  \n",
    "        print(f\"✅ Nouveau meilleur modèle sauvegardé avec val_loss = {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage des valeurs de loss et d'accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot validation losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, marker='o', color='b', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Etape 5 : Evaluation du modèle sur les données de Test, données extérieures à l'apprentissage**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Etape 6 : à vous de jouer !**\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Ce que vous avez fait ici est du **transfer learning**. C'est bien et des fois suffisants pour ses propres besoins, mais il arrive que ca ne suffise pas. Dans ces cas là, il faut **fine-tuner le modèle**, c'est à dire modifier les poids du modèle.\n",
    "\n",
    "<br>\n",
    "\n",
    "Reprenez l'apprentissage en défreezant tout d'abord les couches fully connected, puis les couches convolutives, pour voir l'effet de finetuner le modèle de fondation.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Pouvez-vous déceler dans les nouvelles valeurs de loss train/valid une différence avec le transfer learning?**\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

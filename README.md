# üõ∞Ô∏è Atelier CNN - Classification d'Images Satellites  

## Web API
D√©ployer un mod√®le d'intelligence artificielle via une **API** permet de le rendre **accessible, scalable et facilement int√©grable** dans divers syst√®mes sans avoir besoin de red√©ployer le mod√®le √† chaque utilisation.

### üîπ **Principaux avantages :**  
- **Accessibilit√©** ‚Üí Toute application (web, mobile, backend) peut envoyer des requ√™tes et obtenir des pr√©dictions en temps r√©el.
- **Scalabilit√©** ‚Üí L‚ÄôAPI permet d‚Äôh√©berger le mod√®le sur un serveur centralis√© et de g√©rer plusieurs requ√™tes simultan√©ment.
- **Mise √† jour simplifi√©e** ‚Üí On peut am√©liorer ou remplacer le mod√®le sans impacter les utilisateurs finaux.
- **Interop√©rabilit√©** ‚Üí Le mod√®le peut √™tre utilis√© par des applications √©crites dans diff√©rents langages (Python, JavaScript, Java‚Ä¶).
- **S√©curit√©** ‚Üí L'API contr√¥le qui peut acc√©der au mod√®le et prot√®ge les donn√©es sensibles.  

Un mod√®le de **classification d‚Äôimages satellites** peut √™tre d√©ploy√© sous forme d'API REST. Une application web peut alors envoyer une image via une requ√™te **HTTP POST**, et l‚ÄôAPI renvoie un label (`for√™t`, `mer`, `d√©sert`, `nuageux`) en r√©ponse.

### FastAPI
**FastAPI** est un framework Python rapide et performant pour cr√©er des **API RESTful**. Il est id√©al pour exposer un mod√®le d'IA, car il permet de g√©rer facilement les requ√™tes HTTP, d'assurer une ex√©cution asynchrone optimis√©e et d'int√©grer automatiquement la documentation interactive.

### **Endpoint dans FastAPI**  
Un **endpoint** est une route d√©finie dans FastAPI qui r√©pond √† une requ√™te HTTP (ex: `GET`, `POST`). Il permet d‚Äôex√©cuter une fonction sp√©cifique, comme recevoir une image et retourner une pr√©diction d‚Äôun mod√®le d‚ÄôIA. Il structure l‚ÄôAPI et facilite l‚Äôacc√®s aux services.

### **Uvicorn**  
**Uvicorn** est un serveur ASGI (Asynchronous Server Gateway Interface) qui ex√©cute les applications **FastAPI** de mani√®re ultra-rapide et asynchrone. Il est essentiel pour servir l‚ÄôAPI en production et g√©rer efficacement les requ√™tes entrantes.

## D√©veloppement de la Web API

- recopier le fichier ``.pth`` dans le r√©pertoire ``cnn_app\app\cnn``.

Le fichier ``.pth`` contient un dictionnaire d'√©tats du mod√®le. Un dictionnaire d'√©tat de mod√®le est un dictionnaire Python qui associe chaque couche du mod√®le √† ses param√®tres (poids et biais). Ce dictionnaire ne contient que les param√®tres du mod√®le, pas l'architecture elle-m√™me.

- Ouvrir le fichier ``cnn.py``.

dans le ``try`` recopier le code suivant :
```python
        # Recr√©er l'architecture du mod√®le
        model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)  # False car on charge nos propres poids
        #    Modifier la derni√®re couche du classificateur pour correspondre aux poids entra√Æn√©s
        num_classes =  # Mettre le bon nombre de classes
        model.classifier[3] = torch.nn.Linear(in_features=1024, out_features=num_classes)
```
Ce code indique le mod√®le √† utiliser avec le fichier ``.pth``. Ce mod√®le propose 1000 sortie, il faut rajouter une couche pour passer au nombre de classes utiles √† notre mod√®le. 
**Penseez √† remplir la ligne suivante ``num_classes = ``.**

Il faut ensuite charger notre dictionnaire d'√©tat et d√©marer l'√©valuation pr√©dictive. Ajout``tez ce code √† la suite du pr√©c√©dent, toujours dans le ``try``.
```python
        model_path = # Mettre le bon chemin pour le fichier pth
        model.load_state_dict(torch.load(model_path, map_location=torch.device("cpu")), strict=False)  # Charger les poids
        model.eval()  # Mode √©valuation pour la pr√©diction
```
**Pensez √† remplir la varaible ``model_path`` en indiquant le chemin de votre ``.pth``.**

Apr√®s le ``try : except : `` le code pr√©pare l'image pour sa pr√©diction :
```python
# retrouver la transformation utilis√©e pour entra√Æner le mod√®le
    transform = 

    image = Image.open(file_path).convert("RGB")
    image = transform(image).unsqueeze(0)
```
**Pensez √† retrouver la transformation de l'entrainement pour le recopier ici.**

Enfin, le code fait l'interpr√©tation et r√©cup√®re les r√©sultats.
```python
    output = model(image)
    _, predicted = torch.max(output, 1)

    return 
```
**La variable ``predicted.item()`` contient le code de la classe ayant la meilleur pr√©dition. Nous souhaitons que le retour de la fonction predict_image() soit une chaine de caract√®res gr√¢ce aux dictionnaire LABEL, qui fait conrrespondre les classes √† leurs labels.**

# üõ∞Ô∏è **Atelier CNN - Classification d'Images Satellites**

## **D√©ploiement d'un mod√®le IA via une Web API**
D√©ployer un mod√®le d'intelligence artificielle via une **API** permet de le rendre **accessible, scalable et facilement int√©grable** dans divers syst√®mes, sans avoir besoin de le red√©ployer √† chaque utilisation.

### **Principaux avantages :**
- **Accessibilit√©** ‚Üí Toute application (web, mobile, backend) peut envoyer des requ√™tes et obtenir des pr√©dictions en temps r√©el.
- **Scalabilit√©** ‚Üí L‚ÄôAPI permet d‚Äôh√©berger le mod√®le sur un serveur centralis√© et de g√©rer plusieurs requ√™tes simultan√©ment.
- **Mise √† jour simplifi√©e** ‚Üí On peut am√©liorer ou remplacer le mod√®le sans impacter les utilisateurs finaux.
- **Interop√©rabilit√©** ‚Üí Le mod√®le peut √™tre utilis√© par des applications √©crites dans diff√©rents langages (Python, JavaScript, Java‚Ä¶).
- **S√©curit√©** ‚Üí L'API contr√¥le qui peut acc√©der au mod√®le et prot√®ge les donn√©es sensibles.

**Exemple d‚Äôutilisation :**  
Un mod√®le de **classification d‚Äôimages satellites** peut √™tre expos√© sous forme d'API REST. Une application web peut alors envoyer une image via une requ√™te **HTTP POST**, et l‚ÄôAPI renvoie un label (`For√™t`, `Mer`, `D√©sert`, `Nuageux`) en r√©ponse.
![diagramme de flux](ressources/cnn_flux.drawio.png)

## **FastAPI**
[FastAPI](https://fastapi.tiangolo.com/) est un **framework Python rapide et performant** pour cr√©er des **API RESTful**. Il est id√©al pour **exposer un mod√®le d'IA**, car il permet :
- de g√©rer facilement les requ√™tes HTTP,
- d'assurer une **ex√©cution asynchrone optimis√©e**,
- d'int√©grer automatiquement une **documentation interactive** (`/docs`).
![FastAPI](ressources/fastapi-logo.png)

### **Endpoint dans FastAPI**
Un **endpoint** est une route d√©finie dans FastAPI qui r√©pond √† une requ√™te HTTP (`GET`, `POST`‚Ä¶).  
Il permet d‚Äôex√©cuter une fonction sp√©cifique, comme **recevoir une image et retourner une pr√©diction** d‚Äôun mod√®le d‚ÄôIA.

### **Uvicorn**
[Uvicorn](https://www.uvicorn.org/) est un **serveur ASGI** (Asynchronous Server Gateway Interface) qui ex√©cute les applications **FastAPI** de mani√®re **ultra-rapide** et **asynchrone**.  
Il est essentiel pour **servir l‚ÄôAPI en production** et g√©rer efficacement les requ√™tes entrantes.

---

## **D√©veloppement de la Web API**
Le code source de l‚ÄôAPI se trouve dans le r√©pertoire **`cnn_app/api`**.

### **Installation de l‚Äôenvironnement**
Sur votre machine, commencez par **cr√©er et activer un environnement virtuel** dans ce r√©pertoire :
```bash
python -m venv venv
source venv/bin/activate  # Sur macOS/Linux
venv\Scripts\activate  # Sur Windows
```

### **Installation des d√©pendances**
Installez les biblioth√®ques n√©cessaires √† l'API :
```bash
pip install --upgrade -r requirements.txt
```

### **Ajout du mod√®le de classification**
- **Copiez le fichier `.pth`** (poids du mod√®le) dans le r√©pertoire :  
  `cnn_app/api/app/modele/`
- Ce fichier contient un **dictionnaire d'√©tat du mod√®le**, stockant les **poids et biais** des couches du r√©seau de neurones.

### **Configuration et chargement du mod√®le**
**Ouvrir et compl√©ter `cnn.py`**
Dans le fichier `cnn.py`, ajoutez le code suivant dans le bloc `try` pour **charger le mod√®le MobileNetV3** :

```python
# Recr√©er l'architecture du mod√®le
model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)

# Modifier la derni√®re couche du classificateur pour correspondre au nombre de classes
num_classes = 4  # Nombre de classes : For√™t, Mer, D√©sert, Nuageux
model.classifier[3] = torch.nn.Linear(in_features=1024, out_features=num_classes)
```
**Pourquoi ?**  
Le mod√®le **MobileNetV3** propose **1000 classes par d√©faut**.  
Nous ajoutons une **couche suppl√©mentaire** pour correspondre au **nombre r√©el de classes**.

### **Charger les poids du mod√®le**
Ajoutez ensuite le code suivant pour **charger le fichier `.pth`** et activer le mode √©valuation :

```python
model_path = "app/modele/model.pth"  # Chemin du fichier .pth
model.load_state_dict(torch.load(model_path, map_location=torch.device("cpu")), strict=False)
model.eval()  # Mode √©valuation pour la pr√©diction
```

**Pensez √† bien renseigner le chemin correct vers votre fichier `.pth` !**

### **Pr√©traitement de l‚Äôimage pour la pr√©diction**
Apr√®s le `try: except:`, ajoutez le code suivant pour **pr√©parer l‚Äôimage** :

```python
# Retrouver la transformation utilis√©e pour entra√Æner le mod√®le
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

image = Image.open(file_path).convert("RGB")
image = transform(image).unsqueeze(0)  # Ajoute une dimension batch
```

**Ce code applique les m√™mes transformations** que celles utilis√©es lors de l'entra√Ænement.


### **Interpr√©tation des r√©sultats**
Enfin, ajoutez ce code pour **effectuer la pr√©diction** :

```python
output = model(image)
_, predicted = torch.max(output, 1)

LABELS = {0: "For√™t", 1: "Mer", 2: "D√©sert", 3: "Nuageux"}
return LABELS[predicted.item()]
```

`predicted.item()` **contient l‚Äôindice de la classe pr√©dite**, qu‚Äôon convertit en label gr√¢ce au **dictionnaire `LABELS`**.

## **Mise en place de l'API**
**Fichier `config.py`**
Ce fichier stocke les **constantes de configuration**.  
Par exemple, le dossier o√π enregistrer les images :
```python
UPLOAD_FOLDER = "app/uploads"
```

### **Fichier `main.py`**
Ce fichier contient le **code de l‚ÄôAPI FastAPI**. Exemple de route :
```python
from fastapi import FastAPI

app = FastAPI()

@app.get("/")
async def index():
    return "API Prediction!"
```

### **Endpoint FastAPI pour l‚Äôupload d‚Äôimages**
```python
import os
import shutil
from fastapi import UploadFile, File, HTTPException

os.makedirs(UPLOAD_FOLDER, exist_ok=True)

@app.post("/predictions/satellite/")
async def upload_image(file: UploadFile = File(...)):
    file_path = os.path.join(UPLOAD_FOLDER, file.filename)

    if not file.filename.endswith(("jpg", "jpeg", "png")):
        raise HTTPException(status_code=400, detail="Format non support√©")

    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    label = predict_image(file_path)  # Pr√©diction
    return {"filename": file.filename, "prediction": label}
```

### **Tester l'API**
**Lancer le serveur :**
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8081
```
**Tester l‚ÄôAPI dans le navigateur :**
Acc√©dez √† la documentation interactive :  
`http://127.0.0.1:8081/docs`

![api docs](ressources/api_docs.png)

**Vous pouvez maintenant tester l‚Äôupload d‚Äôimages et obtenir des pr√©dictions √† partir de l'archive tests !**

## navigation
- [Chapitre 4 : Finetuning d'un CNN](https://github.com/Stephane-ISEN/atelierCNN/tree/ch4_cnn_finetuning)
- [Chapitre 6 : Conteneurisation d'une API avec un mod√®le CNN](https://github.com/Stephane-ISEN/atelierCNN/tree/ch6_docker)
